---
# Autonomous Mesh OS - OpenTelemetry Configuration
# Complete observability stack for distributed tracing, metrics, and logging

service:
  name: "autonomous-mesh-os"
  version: "5.0.0"
  namespace: "mesh-os"
  environment: "production"

receivers:
  # OTLP receiver for all telemetry signals
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - "*"
  
  # Prometheus receiver for metrics scraping
  prometheus:
    config:
      scrape_configs:
        - job_name: 'mesh-kernel'
          scrape_interval: 15s
          static_configs:
            - targets: ['localhost:8080']
        
        - job_name: 'agents'
          scrape_interval: 30s
          static_configs:
            - targets: ['localhost:9001', 'localhost:9002', 'localhost:9003']
  
  # Jaeger receiver for legacy trace format
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
  
  # Host metrics receiver
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu: {}
      disk: {}
      filesystem: {}
      load: {}
      memory: {}
      network: {}
      process:
        include:
          match_type: regexp
          names: ["mesh.*", "agent.*"]

processors:
  # Batch processor for efficiency
  batch:
    timeout: 10s
    send_batch_size: 1024
    send_batch_max_size: 2048
  
  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128
  
  # Resource processor to add service information
  resource:
    attributes:
      - key: service.name
        value: "${SERVICE_NAME}"
        action: upsert
      - key: service.version
        value: "${SERVICE_VERSION}"
        action: upsert
      - key: deployment.environment
        value: "${ENVIRONMENT}"
        action: upsert
      - key: mesh.cluster
        value: "${MESH_CLUSTER}"
        action: upsert
  
  # Attributes processor for custom attributes
  attributes:
    actions:
      - key: mesh.tenant
        action: insert
        from_attribute: tenant_id
      - key: mesh.agent_type
        action: insert
        from_attribute: agent_type
      - key: drop_me
        action: delete
  
  # Span processor for traces
  span:
    name:
      from_attributes: ["http.method", "http.route"]
      separator: " "
  
  # Metrics transform processor
  metricstransform:
    transforms:
      - include: .*
        match_type: regexp
        action: update
        operations:
          - action: add_label
            new_label: mesh_cluster
            new_value: "${MESH_CLUSTER}"
  
  # Filter processor to drop unwanted telemetry
  filter:
    traces:
      span:
        - 'attributes["http.route"] == "/health"'
        - 'attributes["http.route"] == "/ping"'
    metrics:
      metric:
        - 'name == "unnecessary.metric"'

exporters:
  # Logging exporter for debugging
  logging:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200
  
  # OTLP exporter for backends
  otlp:
    endpoint: "otel-collector:4317"
    tls:
      insecure: false
      cert_file: /etc/otel/certs/client.crt
      key_file: /etc/otel/certs/client.key
      ca_file: /etc/otel/certs/ca.crt
    headers:
      api-key: "${OTEL_API_KEY}"
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
  
  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: mesh_os
    const_labels:
      environment: "${ENVIRONMENT}"
    send_timestamps: true
    metric_expiration: 5m
    enable_open_metrics: true
  
  # Jaeger exporter for traces
  jaeger:
    endpoint: "jaeger:14250"
    tls:
      insecure: true
  
  # File exporter for local storage
  file:
    path: /var/log/mesh-os/telemetry.json
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 3
  
  # Elasticsearch exporter for logs
  elasticsearch:
    endpoints:
      - "http://elasticsearch:9200"
    index: "mesh-os-logs"
    pipeline: "mesh-os-pipeline"
    authentication:
      user: "${ES_USER}"
      password: "${ES_PASSWORD}"
  
  # CloudWatch exporter (optional)
  awscloudwatch:
    region: "${AWS_REGION}"
    namespace: "MeshOS"
    log_group_name: "/mesh-os/telemetry"
    log_stream_name: "${HOSTNAME}"

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
  
  # Pprof extension for profiling
  pprof:
    endpoint: 0.0.0.0:1777
  
  # zPages extension for debugging
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp, jaeger]
      processors: [memory_limiter, resource, attributes, span, filter, batch]
      exporters: [logging, otlp, jaeger, file]
    
    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics]
      processors: [memory_limiter, resource, metricstransform, filter, batch]
      exporters: [logging, prometheus, otlp, file]
    
    # Logs pipeline
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [logging, elasticsearch, file]
  
  telemetry:
    logs:
      level: info
      encoding: json
      output_paths:
        - stdout
        - /var/log/mesh-os/otel-collector.log
    metrics:
      level: detailed
      address: 0.0.0.0:8888

# Custom semantic conventions for Mesh OS
semantic_conventions:
  # Agent attributes
  mesh.agent.id: "string"
  mesh.agent.type: "string"
  mesh.agent.status: "string"
  mesh.agent.health: "string"
  
  # Job attributes
  mesh.job.id: "string"
  mesh.job.type: "string"
  mesh.job.priority: "string"
  mesh.job.status: "string"
  
  # Policy attributes
  mesh.policy.id: "string"
  mesh.policy.action: "string"
  mesh.policy.result: "string"
  
  # Cost attributes
  mesh.cost.category: "string"
  mesh.cost.amount: "double"
  mesh.cost.currency: "string"
  
  # Carbon attributes
  mesh.carbon.intensity: "double"
  mesh.carbon.region: "string"

# Sampling configuration
sampling:
  # Probabilistic sampler
  probabilistic:
    sampling_percentage: 10  # Sample 10% of traces
  
  # Tail sampling for important traces
  tail_sampling:
    decision_wait: 10s
    num_traces: 100
    expected_new_traces_per_sec: 10
    policies:
      - name: errors
        type: status_code
        status_code:
          status_codes: [ERROR]
      
      - name: slow
        type: latency
        latency:
          threshold_ms: 5000
      
      - name: high_priority
        type: string_attribute
        string_attribute:
          key: mesh.job.priority
          values: [critical, high]
      
      - name: probabilistic
        type: probabilistic
        probabilistic:
          sampling_percentage: 5

# Resource detection
resource_detection:
  detectors: [env, system, docker, ec2, gcp, azure]
  timeout: 5s
  override: false

# Data retention
retention:
  traces:
    ttl: 168h  # 7 days
    max_size: 10GB
  
  metrics:
    ttl: 720h  # 30 days
    max_size: 5GB
  
  logs:
    ttl: 168h  # 7 days
    max_size: 20GB
